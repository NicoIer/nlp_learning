{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from setting import ENG_FRA_PATH\n",
    "import collections\n",
    "import torch\n",
    "import re\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 通用文件读取函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def read_data(path:str,encoding='utf-8'):\n",
    "    with open(path,'r+',encoding=encoding) as file:\n",
    "        return file.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "读取翻译数据对"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "lines = read_data(ENG_FRA_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "处理特殊字符的正则表达式"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "sub_re = re.compile('[\\n\\u202f\\xa0]')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "处理句子的函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def no_space(char, prev_char):\n",
    "    return char in set(',.!?') and prev_char != ' '\n",
    "def process_line(line):\n",
    "    line = sub_re.sub(' ',line).lower().strip()\n",
    "    out = [' ' + char if i > 0 and no_space(char, line[i - 1]) else char for i, char in enumerate(line)]\n",
    "    return ''.join(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "进行转化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "lines = list(map(process_line,lines))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 分词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def tokenize(lines:str):\n",
    "    sources,targets=[],[]\n",
    "    for idx,line in enumerate(lines,0):\n",
    "        source,target = line.split('\\t')\n",
    "        sources.append(source.split())\n",
    "        targets.append(target.split())\n",
    "    return sources,targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "sources,targets = tokenize(lines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 词典"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,tokens:List[List[str]],min_freq,reserved_tokens:List[str]):\n",
    "        \"\"\"\n",
    "        :param tokens:          一列是一句话的分词结果\n",
    "        :param min_freq:        最小词频\n",
    "        :param reserved_tokens: 保留的单词\n",
    "        \"\"\"\n",
    "        # 词频统计\n",
    "        counter = Vocab.count_corpus(tokens)\n",
    "        self._token_freq = sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "        # 转换表\n",
    "        self.idx2token = ['<unk>']+reserved_tokens\n",
    "        self.token2idx = {token:idx for idx,token in enumerate(self.idx2token)}\n",
    "        # 替换低频词\n",
    "        for token,freq in self._token_freq:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            elif token not in self.token2idx:\n",
    "                self.idx2token.append(token)\n",
    "                self.token2idx[token] = len(self.idx2token)-1\n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token2idx.get(tokens,self.unk)\n",
    "        else:\n",
    "            return [self.__getitem__(token) for token in tokens]\n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx2token[indices]\n",
    "        else:\n",
    "            return [self.idx2token[idx] for idx in indices]\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0\n",
    "    @property\n",
    "    def token_freq(self):\n",
    "        return self._token_freq\n",
    "    @classmethod\n",
    "    def count_corpus(cls,tokens):\n",
    "        if len(tokens)!=0 and isinstance(tokens[0],(tuple,list)):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        else:\n",
    "            raise TypeError\n",
    "        return collections.Counter(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "src_vocab = Vocab(sources,2,['<pad>','<bos>','<eos>'])\n",
    "tar_vocab = Vocab(targets,2,['<pad>','<bos>','<eos>'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "句子最大长度"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def max_seq_len(sentences):\n",
    "    if not isinstance(sentences,(list,tuple)):\n",
    "        raise TypeError\n",
    "    return max(sentences,key=lambda x:len(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "'me , too .'"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(max_seq_len(sources))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 语料库"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "class EngFra(Dataset):\n",
    "    def __init__(self, data_path:str, num_example, min_freq:int=2, reserved_tokens:List=None):\n",
    "        # 默认填充词\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        reserved_tokens.extend(['<pad>', '<bos>', '<eos>'])\n",
    "        # 原始语料库\n",
    "        self.sources,self.targets = self._load_data(data_path,num_example)\n",
    "        # 词汇表\n",
    "        self.src_vocab = Vocab(self.sources,min_freq,reserved_tokens)\n",
    "        self.tar_vocab = Vocab(self.targets,min_freq,reserved_tokens)\n",
    "        # 语料库句子最大长度\n",
    "        self.src_seq_len = len(max_seq_len(self.sources)) + 1\n",
    "        self.tar_seq_len = len(max_seq_len(self.targets)) + 1\n",
    "        # 语料预处理-seq2tensor\n",
    "        self.t_src,self.t_tar = self.process_seq(self.src_seq_len,self.tar_seq_len,'<pad>','<eos>',len(self.sources))\n",
    "\n",
    "    def process_seq(self,src_seq_len,tar_seq_len,pad,eos,len):\n",
    "        # 原始语料padding\n",
    "        _1,_2,_3 = [src_seq_len]*len,[pad]*len,[eos]*len\n",
    "        sources = list(map(self.padding,self.sources,_1,_2,_3))\n",
    "        _1 = [tar_seq_len]*len\n",
    "        targets = list(map(self.padding,self.targets,_1,_2,_3))\n",
    "        # padding后的语料转tensor\n",
    "        sources = self.seq2tensor(sources,self.src_vocab)\n",
    "        targets = self.seq2tensor(targets,self.tar_vocab)\n",
    "        return sources,targets\n",
    "\n",
    "    @classmethod\n",
    "    def padding(cls,line:list,seq_len,padding_token:str,eos_token:str):\n",
    "        return line + [eos_token]+ [padding_token]*(seq_len-len(line)),len(line)\n",
    "    @classmethod\n",
    "    def seq2tensor(cls,pairs:tuple,vocab:Vocab):\n",
    "        res = []\n",
    "        for pair in pairs:\n",
    "            seq,valid_len = pair\n",
    "            seq = torch.tensor([vocab[token] for token in seq],dtype=torch.long)\n",
    "            valid_len = torch.tensor(valid_len,dtype=torch.long)\n",
    "            res.append((seq,valid_len))\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _load_data(cls,data_path,num_example=None):\n",
    "        sub_re = re.compile('[\\n\\u202f\\xa0]')\n",
    "        lines = list(map(process_line,read_data(data_path,encoding='utf-8')))\n",
    "        if num_example is None:\n",
    "            return tokenize(lines)\n",
    "        else:\n",
    "            return tokenize(lines[:num_example])\n",
    "    def __getitem__(self, item):\n",
    "        return self.t_src[item],self.t_tar[item]\n",
    "    def __len__(self):\n",
    "        return len(self.sources)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "data = EngFra(data_path=ENG_FRA_PATH,num_example=600,min_freq=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=data,batch_size=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "for idx,pair_data in enumerate(dataloader,0):\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "src,tar = pair_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "src_seq,src_len = src"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "['go', '.', '<eos>', '<pad>', '<pad>', '<pad>']"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data.src_vocab.idx2token[idx] for idx in src_seq[0].detach()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}